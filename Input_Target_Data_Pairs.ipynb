{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "DPXGgqtoYKjm"
      },
      "outputs": [],
      "source": [
        "with open(\"the-verdict.txt\", 'r') as f:\n",
        "  raw_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total number of characters: {len(raw_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkSjGGVHY3qk",
        "outputId": "e1844f0a-9e7a-4e76-b4e3-0735a6cb77b7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 20479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text[:99]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7SJ0bix7Y4zg",
        "outputId": "b8a91e74-5101-4854-aab0-338b3c0ea68f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBqp9_D1kKEF",
        "outputId": "b612b5e7-762c-4b56-87c0-a233745137f9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Input-Target Pairs**"
      ],
      "metadata": {
        "id": "Tkqq0i1NwSL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_text = tokenizer.encode(raw_text)"
      ],
      "metadata": {
        "id": "Cg3vhPerkXUs"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[:50]"
      ],
      "metadata": {
        "id": "buoDZb0Rwnx8"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 4\n",
        "\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size + 1]"
      ],
      "metadata": {
        "id": "YTciGMZZKI4o"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X: {x}\")\n",
        "print(f\"y: {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFbayL9UKUdO",
        "outputId": "67ff203d-5c60-4e5f-bd7c-e31f0dc3a4ea"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: [40, 367, 2885, 1464]\n",
            "y: [367, 2885, 1464, 1807]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size + 1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "\n",
        "  print(f\"Context: {context} ----> Desired: {desired}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve4LyoLULT7C",
        "outputId": "89ffb439-7a94-42a2-cc15-b146075761eb"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: [40] ----> Desired: 367\n",
            "Context: [40, 367] ----> Desired: 2885\n",
            "Context: [40, 367, 2885] ----> Desired: 1464\n",
            "Context: [40, 367, 2885, 1464] ----> Desired: 1807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 10\n",
        "for i in range(1, context_size + 1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "\n",
        "  print(f\"{tokenizer.decode(context)} ---> {tokenizer.decode([desired])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEMMKGTYL0YP",
        "outputId": "6fe1995c-3f7d-47a7-f175-59fda7a3bc28"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I --->  H\n",
            "I H ---> AD\n",
            "I HAD --->  always\n",
            "I HAD always --->  thought\n",
            "I HAD always thought --->  Jack\n",
            "I HAD always thought Jack --->  G\n",
            "I HAD always thought Jack G ---> is\n",
            "I HAD always thought Jack Gis ---> burn\n",
            "I HAD always thought Jack Gisburn --->  rather\n",
            "I HAD always thought Jack Gisburn rather --->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetv1(Dataset):\n",
        "  def __init__(self, text, max_length, stride, tokenizer):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    # Tokenize the entire text\n",
        "    token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    # Use sliding window to chunk the book into overlapping sequences of max_length\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunks = token_ids[i: i + max_length]\n",
        "      target_chunks = token_ids[i + 1: i + max_length + 1]\n",
        "      self.input_ids.append(torch.tensor(input_chunks))\n",
        "      self.target_ids.append(torch.tensor(target_chunks))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, ids):\n",
        "    return self.input_ids[ids], self.target_ids[ids]"
      ],
      "metadata": {
        "id": "kerj4xw-NkmK"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def CreateDataLoader(text, batch_size = 4, max_length = 256, stride = 128, shuffle = True, drop_last = True, num_workers = os.cpu_count()):\n",
        "\n",
        "  # Initialize the tokenizer\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "  # Create Dataset\n",
        "  dataset = GPTDatasetv1(text,  max_length, stride, tokenizer)\n",
        "\n",
        "  # Create DataLoader\n",
        "  dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = shuffle, drop_last = drop_last, num_workers = num_workers)\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "8d-4t6GpiMDR"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = CreateDataLoader(raw_text, batch_size = 8, max_length = 4, stride = 1, shuffle = False)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "input, target = next(data_iter)\n",
        "print(\"Inputs:\\n\", input)\n",
        "print(\"Target:\\n\", target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cmJRr-Gi-wD",
        "outputId": "c09bd987-b129-4a52-cd8d-cfcd4c925aeb"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [  367,  2885,  1464,  1807],\n",
            "        [ 2885,  1464,  1807,  3619],\n",
            "        [ 1464,  1807,  3619,   402],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [  402,   271, 10899,  2138],\n",
            "        [  271, 10899,  2138,   257]])\n",
            "Target:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 2885,  1464,  1807,  3619],\n",
            "        [ 1464,  1807,  3619,   402],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [  402,   271, 10899,  2138],\n",
            "        [  271, 10899,  2138,   257],\n",
            "        [10899,  2138,   257,  7026]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TbBFej0dmMQs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}