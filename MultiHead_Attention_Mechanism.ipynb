{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **SELF ATTENTION WITH TRAINABLE WEIGHTS**"
      ],
      "metadata": {
        "id": "069jzC-Eyk4n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z61AKYlzyjVm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3iKecoR1cHb",
        "outputId": "e7369748-73f6-42f1-ea14-3cd139ac9210"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = inputs[1]\n",
        "d_in = inputs.shape[1]\n",
        "d_out = 2"
      ],
      "metadata": {
        "id": "DFk67Ajzyy1e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "W_query = nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_key = nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_value = nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
      ],
      "metadata": {
        "id": "vCRl0gH-y3bt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"W_query: \\n{W_query}\")\n",
        "print(f\"\\nW_key: \\n{W_key}\")\n",
        "print(f\"\\nW_value: \\n{W_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA1UYzO9y8To",
        "outputId": "086a5e91-81c0-445c-8581-81a67b42c446"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W_query: \n",
            "Parameter containing:\n",
            "tensor([[0.2961, 0.5166],\n",
            "        [0.2517, 0.6886],\n",
            "        [0.0740, 0.8665]])\n",
            "\n",
            "W_key: \n",
            "Parameter containing:\n",
            "tensor([[0.1366, 0.1025],\n",
            "        [0.1841, 0.7264],\n",
            "        [0.3153, 0.6871]])\n",
            "\n",
            "W_value: \n",
            "Parameter containing:\n",
            "tensor([[0.0756, 0.1966],\n",
            "        [0.3164, 0.4017],\n",
            "        [0.1186, 0.8274]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = x @ W_query\n",
        "key = x @ W_key\n",
        "value = x @ W_value"
      ],
      "metadata": {
        "id": "s--yxgLbzds_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For input 2\n",
        "print(f\"query: \\n{query}\")\n",
        "print(f\"\\nkey: \\n{key}\")\n",
        "print(f\"\\nvalue: \\n{value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ien_uqMy03Xo",
        "outputId": "6aa5d0c6-0bf3-423a-abe6-2dbccc5cc684"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: \n",
            "tensor([0.4306, 1.4551])\n",
            "\n",
            "key: \n",
            "tensor([0.4433, 1.1419])\n",
            "\n",
            "value: \n",
            "tensor([0.3951, 1.0037])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **QKV for whole Input**"
      ],
      "metadata": {
        "id": "ClZZs2sf1MEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs @ W_query\n",
        "key = inputs @ W_key\n",
        "value = inputs @ W_value"
      ],
      "metadata": {
        "id": "GNpu8Apu04rV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"query: \\n{query}\")\n",
        "print(f\"\\nkey: \\n{key}\")\n",
        "print(f\"\\nvalue: \\n{value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB_srjUH1Qli",
        "outputId": "10750938-dae9-4340-d376-e4c507692b76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: \n",
            "tensor([[0.2309, 1.0966],\n",
            "        [0.4306, 1.4551],\n",
            "        [0.4300, 1.4343],\n",
            "        [0.2355, 0.7990],\n",
            "        [0.2983, 0.6565],\n",
            "        [0.2568, 1.0533]])\n",
            "\n",
            "key: \n",
            "tensor([[0.3669, 0.7646],\n",
            "        [0.4433, 1.1419],\n",
            "        [0.4361, 1.1156],\n",
            "        [0.2408, 0.6706],\n",
            "        [0.1827, 0.3292],\n",
            "        [0.3275, 0.9642]])\n",
            "\n",
            "value: \n",
            "tensor([[0.1855, 0.8812],\n",
            "        [0.3951, 1.0037],\n",
            "        [0.3879, 0.9831],\n",
            "        [0.2393, 0.5493],\n",
            "        [0.1492, 0.3346],\n",
            "        [0.3221, 0.7863]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = query[1]\n",
        "key_2 = key[1]\n",
        "\n",
        "attn_scores_2 = query_2.dot(key_2)\n",
        "attn_scores_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfPVSK0i1WUL",
        "outputId": "b22b2b66-4f99-413d-8885-82abf18b4e8f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.8524)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_2 = query_2 @ key.T\n",
        "attn_scores_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X420NTuQ3R_N",
        "outputId": "85449b8a-e29d-42f6-c277-5724f70a04c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention scores\n",
        "attn_scores = query @ key.T\n",
        "attn_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoe1J-lj3SaR",
        "outputId": "aee1340b-73c0-4cb5-80a1-47052a711fd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
              "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
              "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
              "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
              "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
              "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyHm7dU33-pu",
        "outputId": "d64e3657-500c-480a-a266-32861095e93e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Attention Weights**"
      ],
      "metadata": {
        "id": "t_HZpM685bhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = key.shape[1]\n",
        "attn_weights = torch.softmax(attn_scores / d_k ** 0.5, dim = -1)\n",
        "print(f\"Attention weights: \\n{attn_weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-dGwQeT4CvO",
        "outputId": "5cc1851a-a4c7-47e2-9472-1e71c7b8bc76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: \n",
            "tensor([[0.1551, 0.2104, 0.2059, 0.1413, 0.1074, 0.1799],\n",
            "        [0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
            "        [0.1503, 0.2256, 0.2192, 0.1315, 0.0914, 0.1819],\n",
            "        [0.1591, 0.1994, 0.1962, 0.1477, 0.1206, 0.1769],\n",
            "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265, 0.1752],\n",
            "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector = attn_weights @ value\n",
        "print(f\"Context Vectors: \\n{context_vector}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UxtgMUn5hv3",
        "outputId": "a763aeb8-0ef6-4b32-ef3d-3782cf7036ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context Vectors: \n",
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Self Attention Complete**"
      ],
      "metadata": {
        "id": "QcrjsIczC0E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    self.W_Query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_Value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_Key = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "  def forward(self, x):\n",
        "    queries = x @ self.W_Query\n",
        "    keys = x @ self.W_Key\n",
        "    values = x @ self.W_Value\n",
        "\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[1] ** 0.5, dim = -1)\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "fSK0rNuJBbh6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sa = SelfAttention(d_in = 3, d_out = 2)\n",
        "print(sa(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZo0KXuYDrRz",
        "outputId": "c031da29-506c-486f-b07a-786f10e150c6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7236, 0.8354],\n",
            "        [0.7308, 0.8426],\n",
            "        [0.7306, 0.8425],\n",
            "        [0.7145, 0.8256],\n",
            "        [0.7170, 0.8303],\n",
            "        [0.7179, 0.8283]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_V2(nn.Module):\n",
        "  def __init__(self, d_in, d_out, qkv_bias = False):\n",
        "    super().__init__()\n",
        "    self.W_Query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_Value = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_Key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = self.W_Key(x)\n",
        "    queries = self.W_Query(x)\n",
        "    values = self.W_Value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[1] ** 0.5, dim = -1)\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "GEFSaNIpEccu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sa = SelfAttention_V2(d_in = 3, d_out = 2)\n",
        "print(sa(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgJo4KZBG_Mr",
        "outputId": "102c3e73-c71c-42db-c39e-7bd6be347697"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2371, 0.7407],\n",
            "        [0.2305, 0.7362],\n",
            "        [0.2307, 0.7364],\n",
            "        [0.2286, 0.7345],\n",
            "        [0.2338, 0.7396],\n",
            "        [0.2269, 0.7328]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hidding Future Words with Causal Attention**"
      ],
      "metadata": {
        "id": "tFoObcjtbXHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        "  #  [0.4419, 0.6515, 0.5683]]\n",
        ")"
      ],
      "metadata": {
        "id": "g76n_WggHBGS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = sa.W_Query(inputs)\n",
        "values = sa.W_Value(inputs)\n",
        "keys = sa.W_Key(inputs)\n",
        "\n",
        "attn_scores = queries @ keys.T\n",
        "attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim = -1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKmNg93pbfbu",
        "outputId": "f9ceab83-2735-4b0f-9200-2db93818181d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1533, 0.1751, 0.1748, 0.1654, 0.1627, 0.1687],\n",
            "        [0.1660, 0.1679, 0.1679, 0.1659, 0.1660, 0.1664],\n",
            "        [0.1657, 0.1682, 0.1681, 0.1658, 0.1659, 0.1664],\n",
            "        [0.1693, 0.1653, 0.1654, 0.1666, 0.1673, 0.1661],\n",
            "        [0.1604, 0.1727, 0.1726, 0.1642, 0.1636, 0.1665],\n",
            "        [0.1722, 0.1628, 0.1629, 0.1675, 0.1685, 0.1660]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = attn_weights.shape[-1]\n",
        "torch.ones(context_length, context_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn82ZeXfc8Zi",
        "outputId": "b4b61119-5065-4148-cc92-0b46d771c3c0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = attn_weights.shape[-1]\n",
        "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LucXEhGzbpFz",
        "outputId": "e583555a-bba0-4c35-e4ff-9807064ed00a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_simple = mask_simple * attn_weights\n",
        "print(masked_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRXkaZ2rcKVg",
        "outputId": "817ca0f3-a7ea-44b9-b6f1-ed4f544f73dc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1533, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1660, 0.1679, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1657, 0.1682, 0.1681, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1693, 0.1653, 0.1654, 0.1666, 0.0000, 0.0000],\n",
            "        [0.1604, 0.1727, 0.1726, 0.1642, 0.1636, 0.0000],\n",
            "        [0.1722, 0.1628, 0.1629, 0.1675, 0.1685, 0.1660]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rows_sum = masked_simple.sum(dim = 1, keepdim = True)\n",
        "masked_simple_norm = masked_simple / rows_sum\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iA-kMNdcVsv",
        "outputId": "d213522b-37bd-4c22-86d0-5bbdc109d3b4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4971, 0.5029, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3300, 0.3350, 0.3349, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2540, 0.2480, 0.2481, 0.2500, 0.0000, 0.0000],\n",
            "        [0.1924, 0.2073, 0.2070, 0.1970, 0.1963, 0.0000],\n",
            "        [0.1722, 0.1628, 0.1629, 0.1675, 0.1685, 0.1660]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using Infinity to mask**"
      ],
      "metadata": {
        "id": "Bf7f3YkBe9zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(torch.ones(context_length, context_length), diagonal = 1)\n",
        "masked = attn_scores.masked_fill(mask.bool(), float(\"-inf\"))\n",
        "print(masked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkYJGU9OeFFJ",
        "outputId": "cee5af75-4383-4db1-994a-5b39ffa03a61"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0327,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
            "        [ 0.0223,  0.0386,    -inf,    -inf,    -inf,    -inf],\n",
            "        [ 0.0252,  0.0465,  0.0462,    -inf,    -inf,    -inf],\n",
            "        [ 0.0006, -0.0333, -0.0329, -0.0221,    -inf,    -inf],\n",
            "        [ 0.0701,  0.1752,  0.1737,  0.1030,  0.0986,    -inf],\n",
            "        [-0.0260, -0.1052, -0.1042, -0.0648, -0.0571, -0.0778]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(masked / keys.shape[-1] ** 0.5, dim =1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oXuTZBCfI0y",
        "outputId": "16f98f3f-fa81-429c-ff81-6c7e02e4fb0f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4971, 0.5029, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3300, 0.3350, 0.3349, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2540, 0.2480, 0.2481, 0.2500, 0.0000, 0.0000],\n",
            "        [0.1924, 0.2073, 0.2070, 0.1970, 0.1963, 0.0000],\n",
            "        [0.1722, 0.1628, 0.1629, 0.1675, 0.1685, 0.1660]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Masking Additional Attention Weights with dropout**"
      ],
      "metadata": {
        "id": "pJP_k_6ihhEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "dropout = nn.Dropout(0.5)\n",
        "example = torch.ones(6, 6)\n",
        "print(\"Before Dropout: \\n\", example)\n",
        "print(\"\\nAfter Dropout: \\n\", dropout(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNjIP5ElgF_Q",
        "outputId": "4ada6b59-bb62-464f-affa-acc17ef41457"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Dropout: \n",
            " tensor([[1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n",
            "\n",
            "After Dropout: \n",
            " tensor([[2., 2., 2., 2., 2., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.],\n",
            "        [0., 0., 2., 0., 2., 0.],\n",
            "        [2., 2., 0., 0., 0., 2.],\n",
            "        [2., 0., 0., 0., 0., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dropout(attn_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XbC7siXhz4i",
        "outputId": "3c943b87-aa11-47dc-a2f7-28a6fabd79c6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.6699, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.4960, 0.0000, 0.4999, 0.0000, 0.0000],\n",
            "        [0.0000, 0.4145, 0.4141, 0.3939, 0.3927, 0.0000],\n",
            "        [0.3444, 0.3257, 0.0000, 0.0000, 0.3369, 0.3320]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Causal Attention Complete**"
      ],
      "metadata": {
        "id": "cRcsfPdqjYYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack((inputs, inputs), dim = 0)"
      ],
      "metadata": {
        "id": "_zPEYjM8ipBH"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V3gHt5BjfZo",
        "outputId": "7cefd684-ebeb-42f8-f58c-78b335ae182a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias = False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_Query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_Value = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_Key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal = 1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_Key(x)\n",
        "    queries = self.W_Query(x)\n",
        "    values = self.W_Value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(1, 2)\n",
        "    attn_scores.masked_fill(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim = -1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "XybciXxWjf0U"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import cpu_count\n",
        "context_length = batch.shape[1]\n",
        "ca = CausalAttention(d_in = 3, d_out = 2, context_length=context_length, dropout=0.0)\n",
        "context_vec = ca(batch)"
      ],
      "metadata": {
        "id": "CK6uABC-mCV6"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_5CqpSemCxR",
        "outputId": "d9b8686a-fc00-41c6-c9a5-584254f749bd"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.2390,  0.1580],\n",
              "         [-0.2445,  0.1625],\n",
              "         [-0.2442,  0.1622],\n",
              "         [-0.2392,  0.1583],\n",
              "         [-0.2351,  0.1549],\n",
              "         [-0.2425,  0.1610]],\n",
              "\n",
              "        [[-0.2390,  0.1580],\n",
              "         [-0.2445,  0.1625],\n",
              "         [-0.2442,  0.1622],\n",
              "         [-0.2392,  0.1583],\n",
              "         [-0.2351,  0.1549],\n",
              "         [-0.2425,  0.1610]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XakG5ipBmFHB",
        "outputId": "84eb109f-6955-41ce-c280-37f28fdc9a78"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Multi-Head Attention**"
      ],
      "metadata": {
        "id": "qO4Q5sC_z-dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias = False):\n",
        "    super().__init__()\n",
        "    self.heads = [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) for _ in range(num_heads)]\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat([head(x) for head in self.heads], dim = -1)"
      ],
      "metadata": {
        "id": "IBgrIhR1nvMs"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = batch.shape[1]\n",
        "d_in, d_out = 3, 2\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, dropout = 0.0, num_heads = 2)\n",
        "context_vecs = mha(batch)"
      ],
      "metadata": {
        "id": "H92PuE2U1RBE"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_vecs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7Ao0HnY1T9F",
        "outputId": "33d01d40-2893-403d-9d11-ea8f31188d50"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3298,  0.2368,  0.0692,  0.1881],\n",
              "         [-0.3278,  0.2369,  0.0741,  0.1855],\n",
              "         [-0.3280,  0.2368,  0.0737,  0.1857],\n",
              "         [-0.3292,  0.2367,  0.0708,  0.1875],\n",
              "         [-0.3324,  0.2352,  0.0636,  0.1906],\n",
              "         [-0.3274,  0.2375,  0.0751,  0.1855]],\n",
              "\n",
              "        [[-0.3298,  0.2368,  0.0692,  0.1881],\n",
              "         [-0.3278,  0.2369,  0.0741,  0.1855],\n",
              "         [-0.3280,  0.2368,  0.0737,  0.1857],\n",
              "         [-0.3292,  0.2367,  0.0708,  0.1875],\n",
              "         [-0.3324,  0.2352,  0.0636,  0.1906],\n",
              "         [-0.3274,  0.2375,  0.0751,  0.1855]]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vecs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFRIfRo71h4n",
        "outputId": "1652d1a4-cf58-4cbd-a45d-4c36b3d4ad24"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Multi-Head Attention with Weight Splits**"
      ],
      "metadata": {
        "id": "BS-_aXwc2nfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias = False):\n",
        "    super().__init__()\n",
        "    assert (d_out % num_heads) == 0, \"d_out must be divisible to num_heads\"\n",
        "\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "\n",
        "    self.W_Query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_Value = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_Key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "\n",
        "    self.out_proj = nn.Linear(d_out, d_out) # Linear Layer to combine outputs\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        'mask',\n",
        "        torch.triu(torch.ones(context_length, context_length), diagonal = 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "\n",
        "    keys = self.W_Key(x)\n",
        "    values = self.W_Value(x)\n",
        "    queries = self.W_Query(x)\n",
        "\n",
        "    # We implicitly split the matrix by adding 'num_heads' dimension\n",
        "    # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "    # Transpose (b, num_heads, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "    keys = keys.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "    queries = queries.transpose(1, 2)\n",
        "\n",
        "    # Scaled dot product attention (Self-Attention) with causal mask\n",
        "    attn_scores = queries @ keys.transpose(2, 3) # Dot product of each head\n",
        "\n",
        "    # Original mask truncated to the number of tokens and converted to boolean\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "    # Use the mask to fill the attention scores\n",
        "    attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(attn_scores / self.head_dim ** 0.5, dim = -1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "    context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "    # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "    context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "R6Q8ftRD1ksj"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "inputs = torch.rand(3, 6)"
      ],
      "metadata": {
        "id": "6Qmv67zHJ1KL"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTb9CCvSGWFs",
        "outputId": "11d3fc4e-2b40-4f4e-da9a-2b08429ac280"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740, 0.8665],\n",
              "        [0.1366, 0.1025, 0.1841, 0.7264, 0.3153, 0.6871],\n",
              "        [0.0756, 0.1966, 0.3164, 0.4017, 0.1186, 0.8274]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack((inputs, inputs), dim = 0)"
      ],
      "metadata": {
        "id": "IFrUb7hMQoYS"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T85zOfWcQuWD",
        "outputId": "067eaf6d-3e0d-40bb-c9af-2c889470ee93"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2961, 0.5166, 0.2517, 0.6886, 0.0740, 0.8665],\n",
              "         [0.1366, 0.1025, 0.1841, 0.7264, 0.3153, 0.6871],\n",
              "         [0.0756, 0.1966, 0.3164, 0.4017, 0.1186, 0.8274]],\n",
              "\n",
              "        [[0.2961, 0.5166, 0.2517, 0.6886, 0.0740, 0.8665],\n",
              "         [0.1366, 0.1025, 0.1841, 0.7264, 0.3153, 0.6871],\n",
              "         [0.0756, 0.1966, 0.3164, 0.4017, 0.1186, 0.8274]]])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usdlS_TTQu3o",
        "outputId": "5fdd642c-7baa-4327-c090-de0d1f0bef58"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, context_length, d_in = batch.shape"
      ],
      "metadata": {
        "id": "is_TnrqDQxnu"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"batch_size: {batch_size}\")\n",
        "print(f\"context_length: {context_length}\")\n",
        "print(f\"d_in: {d_in}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI_nphcmQ3SP",
        "outputId": "48ef67c9-ecee-4c93-9ca2-7a53bc2f5b1b"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size: 2\n",
            "context_length: 3\n",
            "d_in: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_out = 6\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, dropout = 0.0, num_heads = 2)\n",
        "context_vecs = mha(batch)"
      ],
      "metadata": {
        "id": "hXX7_OoZQ42N"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context_vecs)\n",
        "print(f\"\\nContext Vector shape: {context_vecs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdLUe6AeRGyp",
        "outputId": "8cb2ac58-1225-4513-8788-8e1e2348dccc"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.5220,  0.5167,  0.4977,  0.1516,  0.0896,  0.3226],\n",
            "         [-0.4437,  0.4934,  0.5212,  0.1573,  0.1259,  0.3273],\n",
            "         [-0.4483,  0.4875,  0.5042,  0.1744,  0.1281,  0.3392]],\n",
            "\n",
            "        [[-0.5220,  0.5167,  0.4977,  0.1516,  0.0896,  0.3226],\n",
            "         [-0.4437,  0.4934,  0.5212,  0.1573,  0.1259,  0.3273],\n",
            "         [-0.4483,  0.4875,  0.5042,  0.1744,  0.1281,  0.3392]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "\n",
            "Context Vector shape: torch.Size([2, 3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GBIWrUeKRMW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}